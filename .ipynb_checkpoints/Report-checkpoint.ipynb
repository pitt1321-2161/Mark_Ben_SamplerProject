{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTRODUCTION**\n",
    "\n",
    "Inspired by the wave analyses and manipulations that homework 9 required, as well as by our own experiences as musicians, we chose to create what we are calling an autosampler. In a musical context, sampling is the act of selecting and isolating small parts (known as samples) of a recording, and using those samples as part of a new piece of music. Sampling has always been common in the world of hip hop, where drum beat samples are looped and used as a backing track. More recently, some producers of electronic dance music have risen to prominence whose music consists almost entirely of short samples, mixed together and played as their own instrument. In either case, the producer needed to manually create his own samples. Using modern-day software, this is done by simply selecting a starting and an ending point on a recording's sound wave, and taking the part of the wave that lies between those two points. While this process sounds simple enough, it becomes quite tedious when you have large numbers of recordings to analyze, listen to for potential samples, and cut samples from. Our goal in this project is to automatically cut samples from user-provided wave files, and arrange those samples to produce output in the tune of a user-provided melody. For the examples presented in this paper, we have used the melody of Beethoven's well known piece Fur Elise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE DESCRIPTION:**\n",
    "\n",
    "The meat of this project is the functionality of chopping up an input wave into samples, and then properly categorizing and storing the resulting pieces. In our initial, naive approach, we decided to chop the waves such that one sample would have the length of an eighth note, given a predefined tempo in beats per minute. We arbitrarily chose a tempo of 148 beats per minute. This translated to approximately 2.467 beats per second, or 0.2027 seconds per note since the eighth note is traditionally half a beat. Using a standard sampling rate of 44.1 kHz, this meant that each note would be 8939 data points long.\n",
    "\n",
    "With this information, the next step is to iterate over each input wave provided by the user. Using the functions from waveIO.py, each file is read in and unpacked.The wave is then split, as mentioned above, into pieces 8939 data points long. This list of points serves as the samples that will be analyzed, sorted, and built into a final output wave.\n",
    "\n",
    "This list of samples is then iterated over for sorting and storage. Samples shorter than 8939 samples long are discarded, which prevents shortened samples such as those that can occur at the end of a wave from being sorted with the samples of uniform length. The Fourier Transform of the sample is taken using Numpy's fft module, and then divided by the length of the sample in data points to normalize its amplitudes. Numpy'sfftfreq function is used to create the frequency bins for the sample, and the sample's strongest frequency is found.\n",
    "\n",
    "This is where the amplitude normalization becomes important. The amplitude of the strongest frequency is compared to a predefined threshold value. If the amplitude is lower than this threshold, then no frequencies are extracted from the sample. If the amplitude is greater than the threshold, the sample's data is added to a large list of samples, and its index within that list is noted. The sample proceeds with sorting. In that case, the frequency is compared with a dictionary containing baseline frequencies for the twelve semitones in a musical octave. Since the A4 (this notation stands for the note A in the fourth octave, with A being the tenth not in the octave) note with an ideal frequency of 440.0 Hz is typically used as a standard, I used the frequencies of all the fourth octave notes to populate this dictionary.\n",
    "\n",
    "If the sample's frequency is lower than the lowest frequency in the dictionary (with about 1% tolerance), then it must be part of a lower octave. Likewise, if it is higher than the highest frequency in the dictionary (with the same tolerance), it must be part of a higher octave. In the former case, I divide a multiplier value (initially set to 1) by 2 and compare the sample frequency to the highest and lowest frequencies in the dictionary, multiplied by the multiplier value. If the frequency is still too low, I again halve the multiplier, continuing this process until the sample frequency falls between the highest and lowest dictionary frequencies times the multiplier. Alternatively, in the case that the sample frequency was too high, I perform the same process, but double the multiplier instead of halving it on each unsuccessful comparison.\n",
    "\n",
    "Having ascertained the octave of the sample frequency, and with specific values of the multiplier corresponding to specific octaves, the sample can be properly stored. The dictionary of note frequencies is iterated over, with each note's frequency value multiplied by the multiplier from earlier. If the sample frequency is within 1% of this multiplied dictionary value, its index in the larger sample list is stored in a list within a dictionary of the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes_db = {\n",
    "\"A\": [[],[],[],[],[],[]],\n",
    "\"A#\": [[],[],[],[],[],[]],\n",
    "\"B\": [[],[],[],[],[],[]],\n",
    "\"C\": [[],[],[],[],[],[]],\n",
    "\"C#\": [[],[],[],[],[],[]],\n",
    "\"D\": [[],[],[],[],[],[]],\n",
    "\"D#\": [[],[],[],[],[],[]],\n",
    "\"E\": [[],[],[],[],[],[]],\n",
    "\"F\": [[],[],[],[],[],[]],\n",
    "\"F#\": [[],[],[],[],[],[]],\n",
    "\"G\": [[],[],[],[],[],[]],\n",
    "\"G#\":[[],[],[],[],[],[]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where each note has a list of sub-lists, and each sub-list holds the index values of samples that contain the corresponding note in a specific octave.\n",
    "\n",
    "If the code were to stop at this point, it could deal perfectly fine with simple input waves of single notes. Chords, however, would pose a problem, as only one frequency is pulled from each sample. To solve this problem, after the sample is sorted into one of the bins above, the strongest frequency is deleted from the Fourier Transform data, as is the frequency bin that corresponded to that frequency. The octave multiplier is reset to 1, and the next strongest frequency is pulled from the Fourier data. Its amplitude is once again compared to the threshold, and the whole process repeats itself, selecting, sorting, and deleting the strongest frequencies from the sample until the strongest frequency is lower than the threshold. Once this happens, the sample is completely sorted, and the sample's index is stored in bins for each note that was contained within the sample. It is important to note that on these subsequent loops, a frequency will only be added to a bin if the same sample's index does not already appear in that bin. This prevents a sample from being sorted twice into the same note's bin.\n",
    "\n",
    "For example, after completely sorting a sample of a C Major chord in the fourth octave, where all three notes were above threshold and there was no noise above the threshold, the notes_db structure would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    "\"A\": [[],[],[],[],[],[]],\n",
    "\"A#\": [[],[],[],[],[],[]],\n",
    "\"B\": [[],[],[],[],[],[]],\n",
    "\"C\": [[],[],[],[sample_index],[],[]],\n",
    "\"C#\": [[],[],[],[],[],[]],\n",
    "\"D\": [[],[],[],[],[],[]],\n",
    "\"D#\": [[],[],[],[],[],[]],\n",
    "\"E\": [[],[],[],[sample_index],[],[]],\n",
    "\"F\": [[],[],[],[],[],[]],\n",
    "\"F#\": [[],[],[],[],[],[]],\n",
    "\"G\": [[],[],[],[sample_index],[],[]],\n",
    "\"G#\":[[],[],[],[],[],[]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the samples from a given input wave are sorted in this manner, it is time to assemble them into the music the user provided. A sample of the notation used to specify the output music is shown below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "E5\n",
    "D#5\n",
    "#\n",
    "E5\n",
    "D#5\n",
    "E5\n",
    "B4\n",
    "D5\n",
    "C5\n",
    "#\n",
    "A4\n",
    "%\n",
    "%\n",
    "C4\n",
    "E4\n",
    "A4\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example consists of the first few measures of Fur Elise. The notes to be played at a given time appear on each line. \"#\" symbols are used to denote boundaries between measures for convenience of reading and writing, and are ignored by the program. \"%\" symbols denote rests, or periods where no notes are played. Each note or rest has the length of one sample. Chords can be denoted by having multiple notes on the same line, separated by commas.\n",
    "\n",
    "First an empty array is initialized to hold the output wave. Each line of the input music file is isolated and split by comma characters. If the line consists of a \"#\" symbol, the line is ignored and the next line is processed. If the line consists of a \"%\" symbol, a sample-length set of zeros is generated and appended to the output wave. Otherwise, for each note symbol on the line, a random sample index is pulled from the note's corresponding bin. The sample whose index was chosen is appended onto the output wave.\n",
    "\n",
    "Once all the lines have been processed, the output wave is packed and saved under a user-provided filename, using functions from waveIO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Physical Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
